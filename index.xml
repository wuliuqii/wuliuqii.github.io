<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>wuliuqi</title>
    <link>https://wuliuqii.github.io/</link>
    <description>Recent content on wuliuqi</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 07 Apr 2022 08:13:20 +0800</lastBuildDate><atom:link href="https://wuliuqii.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Goleveldb源码分析（五）内存数据库</title>
      <link>https://wuliuqii.github.io/posts/goleveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%BA%94%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
      <pubDate>Thu, 07 Apr 2022 08:13:20 +0800</pubDate>
      
      <guid>https://wuliuqii.github.io/posts/goleveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%BA%94%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93/</guid>
      <description>leveldb中内存数据库用来维护有序的key-value对，其底层是利用跳表实现，绝大多数操作（读／写）的时间复杂度均为O(log n)，有着与平衡树相媲美的操作效率，但是从实现的角度来说简单许多，因此在本文中将介绍一下内存数据库的实现细节。
跳表 关于跳表的详细介绍这里不再展开，想了解的可以去看论文Skip Lists: A Probabilistic Alternative to Balanced Trees，这里只讲Leveldb中的实现。
结构 一个跳表的结构示意图如上所示。
跳表是按层建造的。底层是一个普通的有序链表。每个更高层都充当下面链表的快速通道，这里在层 $i$ 中的元素按某个固定的概率 $p$ (通常为0.5或0.25)出现在层 $i+1$ 中。平均起来，每个元素都在 $1/(1-p)$ 个列表中出现，而最高层的元素（通常是在跳跃列表前端的一个特殊的头元素）在 $O((log1/p)*n)$ 个列表中出现。
goleveldb中的跳表并没有单独抽象为一个结构体，而是嵌入到了DB结构中，同时它使用的实现方式是数组而非链表。这里的kvData数组存储key-value数据项，nodeData数组存储每个节点的链接信息，包括当前节点key-value值在kvData数组中的偏移量，层高，以及每层对应的下一个节点在nodeData中的索引值（下个节点的kv offset的索引值）。
const ( 	nKV = iota // nodeData[0] 	nKey // [1] 	nVal // [2] 	nHeight // [3] 	nNext // [4] )  // 内存数据库 type DB struct { 	// 用来比较key值 	cmp comparer.BasicComparer 	rnd *rand.Rand  	mu sync.</description>
    </item>
    
    <item>
      <title>Goleveldb源码分析（四）日志</title>
      <link>https://wuliuqii.github.io/posts/goleveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%9B%9B%E6%97%A5%E5%BF%97/</link>
      <pubDate>Tue, 05 Apr 2022 09:13:33 +0800</pubDate>
      
      <guid>https://wuliuqii.github.io/posts/goleveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%9B%9B%E6%97%A5%E5%BF%97/</guid>
      <description>为了防止写入内存的数据库因为进程异常、系统掉电等情况发生丢失，Leveldb在写内存之前会将本次写操作的内容写入日志文件中。
在Leveldb中，有两个memory db，以及对应的两份日志文件。其中一个memory db是可读写的，当这个db的数据量超过预定的上限时，便会转换成一个不可写的memory db，与此同时，与之对应的日志文件也变成一份frozen log。
而新生成的immutable memory db则会由后台的minor compaction进程将其转换成一个sstable文件进行持久化，持久化完成，与之对应的frozen log被删除。
在本文中主要分析日志的结构、写入读取操作。
日志结构 为了增加读取效率，日志文件中按照block进行划分，每个block的大小为32KiB。每个block中包含了若干个完整的chunk。
一条日志记录包含一个或多个chunk。每个chunk包含了一个7字节大小的header，前4字节是该chunk的校验码，紧接的2字节是该chunk数据的长度，以及最后一个字节是该chunk的类型。其中checksum校验的范围包括chunk的类型以及随后的data数据。
chunk共有四种类型：full，first，middle，last。一条日志记录若只包含一个chunk，则该chunk的类型为full。若一条日志记录包含多个chunk，则这些chunk的第一个类型为first, 最后一个类型为last，中间包含大于等于0个middle类型的chunk。
由于一个block的大小为32KiB，因此当一条日志文件过大时，会将第一部分数据写在第一个block中，且类型为first，若剩余的数据仍然超过一个block的大小，则第二部分数据写在第二个block中，类型为middle，最后剩余的数据写在最后一个block中，类型为last。
日志写 日志写入流程较为简单，在leveldb内部，实现了一个journal的writer。首先调用Next函数获取一个singleWriter，这个singleWriter的作用就是写入一条journal记录。
singleWriter开始写入时，标志着第一个chunk开始写入。在写入的过程中，不断判断writer中buffer的大小，若超过32KiB，将chunk开始到现在做为一个完整的chunk，为其计算header之后将整个chunk写入文件。与此同时reset buffer，开始新的chunk的写入。
若一条journal记录较大，则可能会分成几个chunk存储在若干个block中。
type Writer struct { 	w io.Writer 	// 充当逻辑时钟 	seq int 	f flusher 	// buf[i:j] 表示当前的chunk，i下标包括chunk header 	i, j int 	// 已经写入的下标 	written int 	// 是否为第一个chunk 	first bool 	// 是否数据已经写入buf，但是还没有落盘（当前block未满32KiB） 	pending bool 	err error 	// 每个block为32KiB 	buf [blockSize]byte }  // chunk header: // +-------------------+-----------------+--------------------+ // | Checksum(4-bytes) | Length(2-bytes) | Chunk type(1-byte) | // +-------------------+-----------------+--------------------+ func (w *Writer) fillHeader(last bool) { 	if w.</description>
    </item>
    
    <item>
      <title>Goleveldb源码分析（三）布隆过滤器</title>
      <link>https://wuliuqii.github.io/posts/goleveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%89%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</link>
      <pubDate>Fri, 01 Apr 2022 08:19:43 +0800</pubDate>
      
      <guid>https://wuliuqii.github.io/posts/goleveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%89%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</guid>
      <description>布隆过滤器是一种空间效率很高的随机数据结构，它利用位数组很简洁地表示一个集合，并能判断一个元素是否属于这个集合。布隆过滤器的这种高效是有一定代价的：在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合（false positive）。因此，布隆过滤器不适合那些零错误的应用场合。而在能容忍低错误率的应用场合下，布隆过滤器通过极少的错误换取了存储空间的极大节省。
Leveldb中利用布隆过滤器判断指定的key值是否存在于sstable中，若过滤器表示不存在，则该key一定不存在，由此加快了查找的效率。
结构 布隆过滤器底层是一个位数组，初始时每一位都是0
当插入值x后，分别利用k个哈希函数（图中为3）利用x的值进行散列，并将散列得到的值与布隆过滤器的容量进行取余，将取余结果所代表的那一位值置为1。
一次查找过程与一次插入过程类似，同样利用k个哈希函数对所需要查找的值进行散列，只有散列得到的每一个位的值均为1，才表示该值“有可能”真正存在；反之若有任意一位的值为0，则表示该值一定不存在。例如y1一定不存在；而y2可能存在。
数学结论1 首先，与布隆过滤器准确率有关的参数有：
 哈希函数的个数k； 布隆过滤器位数组的容量m; 布隆过滤器插入的数据数量n。  主要的数学结论有：
 为了获得最优的准确率，当$k = ln2 * (m/n$)时，布隆过滤器获得最优的准确性； 在哈希函数的个数取到最优时，要让错误率不超过є，m至少需要取到最小值的1.44倍。  实现 goleveldb中，布隆过滤器的定义只是一个int数字
type bloomFilter int 创建一个布隆过滤器时，只需要指定为每个key分配的位数即可，如结论2所示，只要该值（m/n）大于1.44即可，一般可以取10。
func NewBloomFilter(bitsPerKey int) Filter {  return bloomFilter(bitsPerKey) } 创建一个Generator, 这一步中需要指定哈希函数的个数k，可以看到$k = f * ln2$，而$f = m/n$，即数学结论1。
返回的Generator中可以添加新的key信息，调用Generate函数时，将所有的key构建成一个位数组写在指定的位置。
type bloomFilterGenerator struct { 	n int // 插入的数据量 	k uint8 // hash 函数的个数  	keyHashes []uint32 }  func (f bloomFilter) NewGenerator() FilterGenerator {  // Round down to reduce probing cost a little bit.</description>
    </item>
    
    <item>
      <title>Goleveldb源码分析（二）缓存</title>
      <link>https://wuliuqii.github.io/posts/goleveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%BA%8C%E7%BC%93%E5%AD%98/</link>
      <pubDate>Thu, 31 Mar 2022 08:30:43 +0800</pubDate>
      
      <guid>https://wuliuqii.github.io/posts/goleveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%BA%8C%E7%BC%93%E5%AD%98/</guid>
      <description>缓存主要的功能就是减少磁盘IO。Leveldb中使用了一种基于LRUCache的缓存机制，用于缓存：
 已打开的sstable文件对象和相关元数据； sstable中的dataBlock的内容。  整体结构 Leveldb中使用的Cache是一种LRUcache，其结构由两部分内容组成：
 Hash table：用来存储数据； LRU：用来维护数据项的新旧信息。   缓存系统：
// 缓存 type Cache struct { 	mu sync.RWMutex // 读写锁 	mHead unsafe.Pointer // *mNode 指向哈希表 	nodes int32 // 哈希表中的节点个数 	size int32 // 哈希表大小 	cacher Cacher // 缓存策略 	closed bool // 是否关闭 } 缓存策略：
// 缓存策略接口，并发安全 // 以下的缓存皆指缓存策略 type Cacher interface { 	// 缓存容量 	Capacity() int  	// 设置缓存容量 	SetCapacity(capacity int)  	// 添加节点的到缓存中 	Promote(n *Node)  	// 将节点从缓存中删除，并尝试将其从哈希表中删除 	Ban(n *Node)  	// 将节点从缓存中删除 	Evict(n *Node)  	// 将所有给定的命名空间的节点从缓存中删除 	EvictNS(ns uint64)  	// 将缓存中的所有节点删除 	EvictAll()  	// 关闭缓存 	Close() error } 实现 再依次看一下上述各个结构实现与核心方法，以及如何组合在一起对外提供缓存的功能。</description>
    </item>
    
    <item>
      <title>Goleveldb源码分析（一）编码</title>
      <link>https://wuliuqii.github.io/posts/goleveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%80%E7%BC%96%E7%A0%81/</link>
      <pubDate>Thu, 31 Mar 2022 08:30:25 +0800</pubDate>
      
      <guid>https://wuliuqii.github.io/posts/goleveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%80%E7%BC%96%E7%A0%81/</guid>
      <description>研究一下基于Go语言的Leveldb的源码，参考作者的配套wiki。
Leveldb的整体流程如下图所示 基础 先从一些外围基础的概念开始看起。
编码 Leveldb使用encoding/binary标准库对数据进行编解码，这里将详细介绍它的规则。
大小端 字节序简单来说就是多字节对象在内存中的排列顺序，主要分为两种，大端序和小端序。
大端序，高位存在较大地址处。 示例中，最高位字节是0x0A 存储在最低的内存地址处。下一个字节0x0B存在后面的地址处。正类似于十六进制字节从左到右的阅读顺序。
小端序，低位存在较大地址处。 最低位字节是0x0D 存储在最低的内存地址处。后面字节依次存在后面的地址处。
在encoding/binary中定义了字节序的接口，同时也定义了大小端
type ByteOrder interface { 	Uint16([]byte) uint16 	Uint32([]byte) uint32 	Uint64([]byte) uint64 	PutUint16([]byte, uint16) 	PutUint32([]byte, uint32) 	PutUint64([]byte, uint64) 	String() string }  type littleEndian struct{} var LittleEndian littleEndian  type bigEndian struct{} var BigEndian bigEndian 看下编码的实例
package main  import ( 	&amp;#34;encoding/binary&amp;#34; 	&amp;#34;fmt&amp;#34; )  func BigEndian() { // 大端序 	// 二进制形式：0000 0000 0000 0000 0001 0002 0003 0004 	var testInt int32 = 0x01020304 // 十六进制表示 	fmt.</description>
    </item>
    
    <item>
      <title>6.824 Lab2A</title>
      <link>https://wuliuqii.github.io/posts/6.824-lab2a/</link>
      <pubDate>Mon, 10 Jan 2022 23:37:13 +0800</pubDate>
      
      <guid>https://wuliuqii.github.io/posts/6.824-lab2a/</guid>
      <description>6.824 Lab 2A 课程主页: https://pdos.csail.mit.edu/6.824/schedule.html
Lab2: https://pdos.csail.mit.edu/6.824/labs/lab-raft.html
论文: https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf
要求 raft 算法通过领导人机制，将一致性问题分解成了三个相对独立的子问题：
 领导选举 日志复制 安全性  Lab 2A 主要的任务就是实现 raft 的选主算法。
raft 基础 raft 集群中的服务器节点都处于一下三个状态之一：领导人、跟随者和候选人。正常的情况中，系统中应该只有一个领导人，并且其他节点都是跟随者。跟随者被动响应来着领导人或候选人的请求。领导人和客户端交互。候选人在选举新领导人的时候出现。
raft 把时间分割成任意长度的任期。任期用连续的整数标记。每一段任期从一次选举开始，一个或者多个候选人尝试成为领导人。如果一个候选人赢得选举，然后他就在接下来的任期内充当领导人的职责。在某些情况下，一次选举过程会造成选票的瓜分。在这种情况下，这一任期会以没有领导人结束；一个新的任期（和一次新的选举）会很快重新开始。raft 保证了在一个给定的任期内，最多只有一个领导人。
实现 2A 中，只关注选举的过程，所以我们目前仅关注部分参数以及选举和心跳流程。
type Raft struct { 	mu sync.Mutex // Lock to protect shared access to this peer&amp;#39;s state 	peers []*labrpc.ClientEnd // RPC end points of all peers 	persister *Persister // Object to hold this peer&amp;#39;s persisted state 	me int // this peer&amp;#39;s index into peers[] 	dead int32 // set by Kill()  	// 2A.</description>
    </item>
    
    <item>
      <title>XOR</title>
      <link>https://wuliuqii.github.io/posts/xor/</link>
      <pubDate>Thu, 28 Oct 2021 22:57:41 +0800</pubDate>
      
      <guid>https://wuliuqii.github.io/posts/xor/</guid>
      <description>异或运算 最近刷 leetcode 碰到了好几道异或运算（XOR）的题目，本文主要介绍异或运算的含义和应用。
什么是异或运算 异或运算，Exclusive or 或者 exclusive disjunction 是一个逻辑运算，当两个运算子不同（一个为真，另一个为假）的时候才为真。
我们都知道或运算（OR）的运算子只要有一个为真，结果就为真，这样就会有两种情况：
 一个为真，另一个为假 两个都为真  这样 OR 的含义是不明确的，异或运算排除了第二种情况，异或这个名字也因此而来。
性质 基本运算 我们假定 0 为 false，1 为 true，XOR（使用 ^ 表示）的运算真值表如下：
   x y x ^ y     0 0 0   0 1 1   1 0 1   1 1 0    XOR 和 0 任何一个数和 0 XOR 的结果为自身
x ^ 0 = x XOR 和自身 任何一个数和自身 XOR 的结果为 0</description>
    </item>
    
    <item>
      <title>Weekly Contest 264</title>
      <link>https://wuliuqii.github.io/posts/weekly-contest-264/</link>
      <pubDate>Sun, 24 Oct 2021 16:01:03 +0800</pubDate>
      
      <guid>https://wuliuqii.github.io/posts/weekly-contest-264/</guid>
      <description>第 264 场周赛 https://leetcode-cn.com/contest/weekly-contest-264?utm_campaign=weekly_contest_2021_cider_264&amp;amp;utm_medium=leetcode_message&amp;amp;utm_source=message&amp;amp;gio_link_id=Y9JBn239
句子中的有效单词 https://leetcode-cn.com/problems/number-of-valid-words-in-a-sentence/
思路 直接模拟
代码 func countValidWords(sentence string) int { 	res := 0 	tokens := strings.Fields(sentence) // 按照空格划分 	for _, token := range tokens { 	if isValid(token) { 	res++ 	} 	} 	return res }  func isValid(token string) bool { 	if strings.ContainsAny(token, &amp;#34;0123456789&amp;#34;) { // 不能有数字 	return false 	}  	n := len(token) 	i := strings.</description>
    </item>
    
    <item>
      <title>6.824 lab1</title>
      <link>https://wuliuqii.github.io/posts/6.824-lab1/</link>
      <pubDate>Sun, 09 May 2021 20:30:53 +0800</pubDate>
      
      <guid>https://wuliuqii.github.io/posts/6.824-lab1/</guid>
      <description>6.824 Lab 1 课程主页: https://pdos.csail.mit.edu/6.824/schedule.html
Lab1: https://pdos.csail.mit.edu/6.824/labs/lab-mr.html
论文: http://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf
要求 lab 1 主要是实现一个简易版 MapReduce 系统，主要有两部分：
 worker：map、reduce 函数执行 ，文件读写处理 coordinate：任务调度 测试用例会有任务超时和 crash 的情况，需要有容错机制  整个流程大概可以简化成如下几步：
 启动 coordinate 进程，监听 worker 请求 启动单个或多个 worker 进程，worker 向 coordinate 请求任务 coordinate 处理 worker 的任务请求，步骤如下：  判断 map 任务是否全部完成 若未完成，挑选一个未完成的 map 任务，并将该任务状态设置为 assigned；否则判断 reduce 任务是否全部完成 若未完成，挑选一个未完成的 reduce 任务，并将该任务状态设置为 assigned   worker 收到任务后，根据任务类型执行对应的函数（map、reduce、wait） worker 完成任务后，向 coordinate 发送任务已完成 coordinate 将相应完成的任务的状态标记为 finished 重复 1-6 直至所有任务完成  worker worker 不断向 coordinate 请求任务，根据返回的任务进行处理，主体程序如下：</description>
    </item>
    
    <item>
      <title>Ostep  Virtualization</title>
      <link>https://wuliuqii.github.io/posts/ostep--virtualization/</link>
      <pubDate>Thu, 02 Apr 2020 10:34:27 +0800</pubDate>
      
      <guid>https://wuliuqii.github.io/posts/ostep--virtualization/</guid>
      <description>CPU 虚拟化 操作系统通过低级机制和高级策略实现 CPU 虚拟化。机制就是一些低级方法和协议，如上下切换，时分共享。策略是在操作系统中作出某种决定的算法。
 你可以将机制看 成为系统的“如何（how）”问题提供答案。例如，操作系统如何执行上下文切换？策略为“哪个（which）” 问题提供答案。例如，操作系统现在应该运行哪个进程？将两者分开可以轻松地改变策略，而不必重新考虑机制，因此这是一种模块化（modularity）的形式，一种通用的软件设计原则。
 进程 进程：运行中的程序。
进程 API 包括：创建（create）、销毁（destroy）、等待（wait）、其他控制（miscellaneous control）、状态（statu）。
进程创建 操作系统如何启动并运行一个进程？
操作系统运行程序必须做的第一件事是将代码和所有静态数据（例如初始化变量）加载到内存中，加载到进程的地址空间中。程序最初以某种可执行格式驻留在磁盘上 （disk，或者在某些现代系统中，在基于闪存的 SSD 上）。因此，将程序和静态数据加载到内存中的过程，需要操作系统从磁盘读取这些字节，并将它们放在内存中的某处（见下图）
将代码和静态数据加载到内存后，操作系统在运行此进程之前还需要执行其他一些操作，为程序的运行时栈（runtime stack）和堆分配一些内存。在 C 程序使用栈存放局部变量、函数参数和返回地址。操作系统分配这些内存，并提供给进程。 操作系统也可能会用参数初始化栈。具体来说，它会将参数填入 main()函数，即 argc 和 argv 数组。堆用于显式请求的动态分配数据。程序通过调用 malloc() 来请求这样的空间，并通过调用 free() 来明确地释放它。数据结构（如链表、散列表、树和其他有趣的数据结构）需要堆。起初堆会很小。随着程序运行，通过 malloc() 请求更多内存，操作系统可能会参与分配更多内存给进程，以满足这些调用。
操作系统还将执行一些其他初始化任务，特别是与输入/输出（I/O）相关的任务。例如，在 UNIX 系统中，默认情况下每个进程都有 3 个打开的文件描述符（file descriptor），用于标准输入、输出和错误。
通过将代码和静态数据加载到内存中，通过创建和初始化栈以及执行与 I/O 设置相关的其他工作，OS 现在（终于）为程序执行搭好了舞台。然后它有最后一项任务：启动程序， 在入口处运行，即 main()。通过跳转到 main()例程，OS 将 CPU 的控制权转移到新创建的进程中，从而程序开始执行。
进程状态 进程可以处于以下 3 种状态之一。
  运行（running）：在运行状态下，进程正在处理器上运行。这意味着它正在执行指令。
  就绪（ready）：在就绪状态下，进程已准备好运行，但由于某种原因，操作系统选择不在此时运行。
  阻塞（blocked）：在阻塞状态下，一个进程执行了某种操作，直到发生其他事件时才会准备运行。一个常见的例子是，当进程向磁盘发起 I/O 请求时，它会被阻塞， 因此其他进程可以使用处理器。</description>
    </item>
    
    <item>
      <title>Python GIL 的前世今生</title>
      <link>https://wuliuqii.github.io/posts/python-gil-%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/</link>
      <pubDate>Mon, 30 Mar 2020 10:10:58 +0800</pubDate>
      
      <guid>https://wuliuqii.github.io/posts/python-gil-%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/</guid>
      <description>简而言之，Python 的全局解释器（GIL）是一种互斥锁，它仅允许一个线程持有 Python 解释器的控制权。这意味着在任何时间点只有一个线程处于执行状态。对于执行单线程程序的开发人员而言，GIL 的影响并不明显，但它可能是 CPU 密集和多线程代码的性能瓶颈。
由于即使在具有多个 CPU 内核的多线程体系结构中，GIL 一次仅允许一个线程执行，GIL 因此以 Python 的“臭名昭著”功能而闻名。
在本文中，您将学习到 GIL 如何影响 Python 程序的性能，以及如何减轻 GIL 对代码的影响。本文所有代码运行环境为
[I] ➜ python --version Python 3.7.6 GIL 为 Python 解决了什么问题 Python 使用引用计数进行内存管理。这意味着用 Python 创建的对象具有引用计数变量，该变量跟踪指向该对象的引用数，当词计数到达零时，将释放该对象占用的内存。
下面是一个简短的代码示例，以演示引用计数的工作原理：
&amp;gt;&amp;gt;&amp;gt; a = [] &amp;gt;&amp;gt;&amp;gt; b = a &amp;gt;&amp;gt;&amp;gt; sys.getrefcount(a) 3 在上面示例中，空列表对象 [] 的引用计数为3，它被 a，b 和传入 sys.getrefcount() 的参数引用。
回到GIL：
问题在于该引用计数变量需要保护，以防止两个线程同时增加或减少其值的竞争状态。如果发生这种情况，则可能导致未释放的内存泄漏，更糟糕的是，在仍然存在对该对象引用的情况下，错误地释放了内存。这可能会导致程序崩溃或其他奇怪的错误。
通过将锁添加到跨线程共享的所有数据结构中，以确保它们不会被不一致地修改，可以保持此引用计数变量的安全。但是对每个对象或者对象组加锁意味着多个锁将同时存在，这将导致另外一个问题——死锁（死锁只可能发生在有多个锁的情况下）。另一个副作用就是重复的请求和释放锁而导致性能降低。
GIL 是解释器本身的单一锁，它添加了一个规则，即任何 Python 字节码的执行都需要获取解释锁。这可以防止死锁（因为只有一个锁），并且不会带来太多的性能开销。但它也会使所有 CPU 密集型的 Python 程序成为单线程。
尽管解释器用于其他语言（例如 Ruby），但 GIL 并不是解决次问题的唯一方法。某些语言通过使用引用计数以外的方法（例如垃圾回收）来避免使用 GIL 对线程安全的内存管理。另一方面，这意味着这些语言必须通过添其他性能提升功能（例如 JIT 编译器）来弥补 GIL 的单线程性能优势的损失。</description>
    </item>
    
  </channel>
</rss>
